{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 31\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from counternet.import_essentials import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dict2json(dictionary: Dict[str, Any], file_name: str):\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        json.dump(dictionary, outfile, indent=4)\n",
    "\n",
    "\n",
    "def load_configs(file_name: Path):\n",
    "    # if os.path.exists(file_name):\n",
    "    #     raise FileNotFoundError(f\"{file_name} is not found.\")\n",
    "    with open(file_name) as json_file:\n",
    "        return json.load(json_file)\n",
    "\n",
    "\n",
    "def update_json_file(param: dict, file_name: str):\n",
    "    if os.path.exists(file_name):\n",
    "        old_param = load_configs(file_name)\n",
    "    else:\n",
    "        old_param = {}\n",
    "    # copy to old_param\n",
    "    for k in param.keys():\n",
    "        old_param[k] = param[k]\n",
    "    dict2json(old_param, file_name)\n",
    "    return old_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_transform(df: pd.DataFrame, cat_cols: list, outcome_col: str):\n",
    "    \"\"\"construct features to [[--cont_features--], [--cat_features--], outcome_col]\"\"\"\n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    assert outcome_col in cols\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        cols.remove(col)\n",
    "    cols.remove(outcome_col)\n",
    "    cols += cat_cols\n",
    "    cols += [outcome_col]\n",
    "    return df[cols]\n",
    "\n",
    "def simple_init_params(cols: list, cat_cols: list, outcome_col: str, file_name: str):\n",
    "    # load configs of adult for no reasons\n",
    "    param = load_json(\"assets/configs/adult.json\")\n",
    "    for col in cat_cols:\n",
    "        cols.remove(col)\n",
    "    cols.remove(outcome_col)\n",
    "    # copy to cont_cols\n",
    "    cont_cols = cols\n",
    "    param['continous_cols'] = cont_cols\n",
    "    param['cat_cols'] = cat_cols\n",
    "    return update_json_file(param, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def bn_func(x1, x2, x3, x4):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    return sigmoid(10.5 * ((x1 * x2) / 8100) + 10 - np.random.normal(1, 0.1, 10000) * x3 + 1e-3 * x4)\n",
    "\n",
    "\n",
    "def x1_to_x3(x1):\n",
    "    return 1/3 * x1 - 5\n",
    "\n",
    "\n",
    "def x1x2_to_x4(x1, x2):\n",
    "    return x1 * np.log(x2 ** 2) / 10 - 10\n",
    "\n",
    "\n",
    "def bn_gen():\n",
    "    \"\"\"\n",
    "    modify code from: https://github.com/divyat09/cf-feasibility/blob/master/generativecf/scripts/simple-bn-gen.py\n",
    "    \"\"\"\n",
    "    x1 = np.random.normal(50, 15, 10000)\n",
    "    x2 = np.random.normal(35, 17, 10000)\n",
    "    x3 = x1_to_x3(x1) + np.random.normal(0, 1, 10000)\n",
    "    x4 = x1x2_to_x4(x1, x2) + np.random.normal(0, 1, 10000)\n",
    "    y = bn_func(x1, x2, x3, x4)\n",
    "\n",
    "    data = np.zeros((x1.shape[0], 5))\n",
    "    data[:, 0] = x1\n",
    "    data[:, 1] = x2\n",
    "    data[:, 2] = x3\n",
    "    data[:, 3] = x4\n",
    "    data[:, 4] = np.array(y > .5, dtype=np.int)\n",
    "    return pd.DataFrame(data, columns=['x1', 'x2', 'x3', 'x4', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_adult_income_dataset(path=None):\n",
    "    \"\"\"Loads adult income dataset from https://archive.ics.uci.edu/ml/datasets/Adult and prepares the data for data analysis based on https://rpubs.com/H_Zhu/235617\n",
    "    :return adult_data: returns preprocessed adult income dataset.\n",
    "\n",
    "    copy from https://github.com/interpretml/DiCE/blob/master/dice_ml/utils/helpers.py\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        raw_data = np.genfromtxt(\n",
    "            'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n",
    "            delimiter=', ',\n",
    "            dtype=str\n",
    "        )\n",
    "    else:\n",
    "        raw_data = np.genfromtxt(\n",
    "            path,\n",
    "            delimiter=', ',\n",
    "            dtype=str\n",
    "        )\n",
    "\n",
    "    #  column names from \"https://archive.ics.uci.edu/ml/datasets/Adult\"\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num',\n",
    "                    'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "                    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "    adult_data = pd.DataFrame(raw_data, columns=column_names)\n",
    "\n",
    "    # For more details on how the below transformations are made, please refer to https://rpubs.com/H_Zhu/235617\n",
    "    adult_data = adult_data.astype(\n",
    "        {\"age\": np.int64, \"educational-num\": np.int64, \"hours-per-week\": np.int64})\n",
    "\n",
    "    adult_data = adult_data.replace(\n",
    "        {'workclass': {'Without-pay': 'Other/Unknown', 'Never-worked': 'Other/Unknown'}})\n",
    "    adult_data = adult_data.replace({'workclass': {\n",
    "                                    'Federal-gov': 'Government', 'State-gov': 'Government', 'Local-gov': 'Government'}})\n",
    "    adult_data = adult_data.replace(\n",
    "        {'workclass': {'Self-emp-not-inc': 'Self-Employed', 'Self-emp-inc': 'Self-Employed'}})\n",
    "    adult_data = adult_data.replace(\n",
    "        {'workclass': {'Never-worked': 'Self-Employed', 'Without-pay': 'Self-Employed'}})\n",
    "    adult_data = adult_data.replace({'workclass': {'?': 'Other/Unknown'}})\n",
    "\n",
    "    adult_data = adult_data.replace({'occupation': {'Adm-clerical': 'White-Collar', 'Craft-repair': 'Blue-Collar',\n",
    "                                                    'Exec-managerial': 'White-Collar', 'Farming-fishing': 'Blue-Collar',\n",
    "                                                    'Handlers-cleaners': 'Blue-Collar',\n",
    "                                                    'Machine-op-inspct': 'Blue-Collar', 'Other-service': 'Service',\n",
    "                                                    'Priv-house-serv': 'Service',\n",
    "                                                    'Prof-specialty': 'Professional', 'Protective-serv': 'Service',\n",
    "                                                    'Tech-support': 'Service',\n",
    "                                                    'Transport-moving': 'Blue-Collar', 'Unknown': 'Other/Unknown',\n",
    "                                                    'Armed-Forces': 'Other/Unknown', '?': 'Other/Unknown'}})\n",
    "\n",
    "    adult_data = adult_data.replace({'marital-status': {'Married-civ-spouse': 'Married',\n",
    "                                                        'Married-AF-spouse': 'Married', 'Married-spouse-absent': 'Married', 'Never-married': 'Single'}})\n",
    "\n",
    "    adult_data = adult_data.replace({'race': {'Black': 'Other', 'Asian-Pac-Islander': 'Other',\n",
    "                                              'Amer-Indian-Eskimo': 'Other'}})\n",
    "\n",
    "    adult_data = adult_data[['age', 'hours-per-week', 'workclass', 'education', 'marital-status',\n",
    "                             'occupation', 'race', 'gender', 'income']]\n",
    "\n",
    "    adult_data = adult_data.replace({'income': {'<=50K': 0, '>50K': 1}})\n",
    "\n",
    "    adult_data = adult_data.replace({'education': {'Assoc-voc': 'Assoc', 'Assoc-acdm': 'Assoc',\n",
    "                                                   '11th': 'School', '10th': 'School', '7th-8th': 'School', '9th': 'School',\n",
    "                                                   '12th': 'School', '5th-6th': 'School', '1st-4th': 'School', 'Preschool': 'School'}})\n",
    "\n",
    "    adult_data = adult_data.rename(\n",
    "        columns={'marital-status': 'marital_status', 'hours-per-week': 'hours_per_week'})\n",
    "\n",
    "    return adult_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OULAD\n",
    "\n",
    "oulad data should be put under directory `data/oulad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_learning_analytic_data(path='assets/data/oulad'):\n",
    "    def weighted_score(x):\n",
    "        d = {}\n",
    "        total_weight = sum(x['weight'])\n",
    "        d['weight'] = total_weight\n",
    "        if sum(x['weight']) == 0:\n",
    "            d['weighted_score'] = sum(x['score']) / len(x['score'])\n",
    "        else:\n",
    "            d['weighted_score'] = sum(\n",
    "                x['score'] * x['weight']) / sum(x['weight'])\n",
    "        return pd.DataFrame(d, index=[0])\n",
    "\n",
    "    def clicks(x):\n",
    "        types = x['activity_type']\n",
    "        sum_clicks = x['sum_click']\n",
    "    #     for t, c in zip(types, sum_clicks):\n",
    "    #         x[f\"{t}_click\"] = c\n",
    "        return pd.DataFrame({f\"{t}_click\": c for t, c in zip(types, sum_clicks)}, index=[0])\n",
    "\n",
    "    print('loading pandas dataframes...')\n",
    "\n",
    "    assessment = pd.read_csv(f'{path}/assessments.csv')\n",
    "    courses = pd.read_csv(f'{path}/courses.csv')\n",
    "    student_assessment = pd.read_csv(f'{path}/studentAssessment.csv')\n",
    "    student_info = pd.read_csv(f'{path}/studentInfo.csv')\n",
    "    student_regist = pd.read_csv(f'{path}/studentRegistration.csv')\n",
    "    student_vle = pd.read_csv(f'{path}/studentVle.csv')\n",
    "    vle = pd.read_csv(f'{path}/vle.csv')\n",
    "\n",
    "    print('preprocessing assessment...')\n",
    "\n",
    "    # note: only count for submitted assessment, not weighted for unsubmitted ones\n",
    "    assessment_merged = student_assessment.merge(assessment)\n",
    "    assessment_grouped = assessment_merged.groupby(\n",
    "        ['code_module', 'code_presentation', 'id_student']).apply(weighted_score)\n",
    "    assessment_df = assessment_grouped.reset_index(\n",
    "        None).drop(['level_3'], axis=1)\n",
    "\n",
    "    print('preprocessing vle...')\n",
    "\n",
    "    # vle\n",
    "    grouped_vle = student_vle.merge(vle).groupby(\n",
    "        ['activity_type', 'code_module', 'code_presentation', 'id_student'])\n",
    "    sumed_vle = grouped_vle.sum().drop(\n",
    "        ['id_site', 'date', 'week_from', 'week_to'], axis=1).reset_index()\n",
    "    grouped_vle = sumed_vle.groupby(\n",
    "        ['code_module', 'code_presentation', 'id_student']).apply(clicks)\n",
    "    vle_df = grouped_vle.reset_index(None).drop(['level_3'], axis=1)\n",
    "\n",
    "    student_df = student_info.merge(assessment_df, on=['code_module', 'code_presentation', 'id_student'], how='left')\\\n",
    "        .merge(vle_df, on=['code_module', 'code_presentation', 'id_student'], how='left')\n",
    "\n",
    "    return student_df[['num_of_prev_attempts', 'weight', 'weighted_score',\n",
    "                       'forumng_click', 'homepage_click', 'oucontent_click',\n",
    "                       'resource_click', 'subpage_click', 'url_click', 'dataplus_click',\n",
    "                       'glossary_click', 'oucollaborate_click', 'quiz_click',\n",
    "                       'ouelluminate_click', 'sharedsubpage_click', 'questionnaire_click',\n",
    "                       'page_click', 'externalquiz_click', 'ouwiki_click', 'dualpane_click',\n",
    "                       'folder_click', 'repeatactivity_click', 'htmlactivity_click',\n",
    "                       'code_module', 'gender', 'region',\n",
    "                       'highest_education', 'imd_band', 'age_band', 'studied_credits',\n",
    "                       'disability', 'final_result']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HELOC\n",
    "\n",
    "home equity line of credit\n",
    "https://community.fico.com/s/explainable-machine-learning-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default of credit card clients\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Credit Card Dataset\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Performance\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "https://dash-xai.herokuapp.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart\n",
    "\n",
    "https://www.kaggle.com/andrewmvd/heart-failure-clinical-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic\n",
    "\n",
    "https://www.kaggle.com/ak1352/titanic-cl?select=train_cl.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breast-cancer-wisconsin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    (\"adult\", load_json(\"assets/configs/adult.json\")),\n",
    "    (\"home\", load_json(\"assets/configs/home.json\")),\n",
    "    (\"student\", load_json(\"assets/configs/student.json\")),\n",
    "    (\"breast_cancer\", load_json(\"assets/configs/extra/breast_cancer.json\")),\n",
    "    (\"credit_card\", load_json(\"assets/configs/extra/credit_card.json\")),\n",
    "    (\"german_credit\", load_json(\"assets/configs/extra/german_credit.json\")),\n",
    "    (\"heart\", load_json(\"assets/configs/extra/heart.json\")),\n",
    "    (\"student_performance\", load_json(\"assets/configs/extra/student_performance.json\")),\n",
    "    (\"titanic\", load_json(\"assets/configs/extra/titanic.json\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def describe(configs: List[Dict[str, Dict[str, Any]]]):\n",
    "    r = {\"size\": {}, \"# of Cont\": {}, \"# of Cat\": {}}\n",
    "    for data_name, config in configs:\n",
    "        data = pd.read_csv(f\"{config['data_dir']}\")\n",
    "        data_size = len(data)\n",
    "        cat_len = len(config['discret_cols'])\n",
    "        cont_len = len(config['continous_cols'])\n",
    "        r['size'][data_name] = data_size\n",
    "        r['# of Cont'][data_name] = cont_len\n",
    "        r['# of Cat'][data_name] = cat_len\n",
    "\n",
    "    # pd.DataFrame.from_dict(r).to_csv(\"../results/data_describe.csv\")\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': {'adult': 32561,\n",
       "  'home': 10459,\n",
       "  'student': 32593,\n",
       "  'breast_cancer': 569,\n",
       "  'credit_card': 30000,\n",
       "  'german_credit': 1000,\n",
       "  'heart': 299,\n",
       "  'student_performance': 649,\n",
       "  'titanic': 891},\n",
       " '# of Cont': {'adult': 2,\n",
       "  'home': 21,\n",
       "  'student': 23,\n",
       "  'breast_cancer': 30,\n",
       "  'credit_card': 20,\n",
       "  'german_credit': 7,\n",
       "  'heart': 7,\n",
       "  'student_performance': 2,\n",
       "  'titanic': 2},\n",
       " '# of Cat': {'adult': 6,\n",
       "  'home': 2,\n",
       "  'student': 8,\n",
       "  'breast_cancer': 0,\n",
       "  'credit_card': 3,\n",
       "  'german_credit': 13,\n",
       "  'heart': 5,\n",
       "  'student_performance': 14,\n",
       "  'titanic': 24}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
