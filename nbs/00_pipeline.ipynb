{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from counternet.import_essentials import *\n",
    "from counternet.utils import *\n",
    "from counternet.training_module import BaseModule, CFNetTrainingModule\n",
    "from counternet.model import BaselinePredictiveModel, CounterNetModel\n",
    "from counternet.cf_explainer import ExplainerBase, LocalExplainerBase, GlobalExplainerBase, VanillaCF\n",
    "from counternet.evaluation import SensitivityMetric, proximity\n",
    "\n",
    "logging.getLogger('pytorch_lightning').setLevel(logging.ERROR)\n",
    "pl_logger = logging.getLogger(\"pytorch_lightning.core\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_trained_model(module: BaseModule, checkpoint_path: str, gpus : int = 0) -> BaseModule:\n",
    "    # assuming checkpoint_path = f\"{dict_path}/epoch={n_epoch}-step={step}.ckpt\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f'{checkpoint_path} is not found.')\n",
    "\n",
    "    n_iter = int(checkpoint_path.split(\"-\")[0].split(\"=\")[-1]) + 1\n",
    "    # model = module.load_from_checkpoint(checkpoint_path)\n",
    "    tmp_trainer = pl.Trainer(\n",
    "        max_epochs=n_iter, resume_from_checkpoint=checkpoint_path, num_sanity_val_steps=0, gpus=gpus,\n",
    "        logger=False, checkpoint_callback=False\n",
    "    )\n",
    "    tmp_trainer.fit(module)\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModelTrainer(object):\n",
    "    def __init__(self,\n",
    "                 model: BaseModule,\n",
    "                 t_configs: Dict[str, Any],\n",
    "                 callbacks: Optional[List[Callback]] = None,\n",
    "                 description: Optional[str] = None,\n",
    "                 debug: Optional[bool] = False,\n",
    "                 logger: Optional[Union[LightningLoggerBase, bool]] = None,\n",
    "                 logger_name: str = \"debug\"):\n",
    "\n",
    "        if logger is None:\n",
    "            logger = pl_loggers.TestTubeLogger(\n",
    "                Path('log/'), name=logger_name,\n",
    "                description=description, debug=debug, log_graph=True\n",
    "            )\n",
    "\n",
    "        # model checkpoint\n",
    "        self.checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='val/val_loss', save_top_k=3, mode='min'\n",
    "        )\n",
    "\n",
    "        # define callbacks\n",
    "        if callbacks is None:\n",
    "            callbacks = [self.checkpoint_callback]\n",
    "        elif self._has_no_model_checkpoint(callbacks):\n",
    "            callbacks += [self.checkpoint_callback]\n",
    "\n",
    "        self.trainer = pl.Trainer(logger=logger, callbacks=callbacks, **t_configs)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def _has_no_model_checkpoint(self, callbacks: List[Callback]) -> bool:\n",
    "        for callback in callbacks:\n",
    "            if isinstance(callback, ModelCheckpoint):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def fit(self, is_parallel=False):\n",
    "        if is_parallel:\n",
    "            logging.warning(\n",
    "                f\"parallel version has not been implemented\\nUsing the single process training...\")\n",
    "        self.trainer.fit(self.model)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def save_best_model(self, dir_path: Path):\n",
    "        if not dir_path.is_dir():\n",
    "            raise ValueError(f\"'{dir_path}' is not a directory\")\n",
    "        best_model_path = Path(self.checkpoint_callback.best_model_path)\n",
    "        shutil.copy(best_model_path, dir_path)\n",
    "        return best_model_path\n",
    "\n",
    "    def load_trained_model(self, checkpoint_path: str, gpus: int = 0) -> BaseModule:\n",
    "        self.model = load_trained_model(\n",
    "            self.model, checkpoint_path=checkpoint_path, gpus=gpus)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "x_cont: torch.Size([32561, 2]), x_cat: torch.Size([32561, 27])\n",
      "categories: [array(['Government', 'Other/Unknown', 'Private', 'Self-Employed'],\n",
      "      dtype=object), array(['Assoc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n",
      "       'Prof-school', 'School', 'Some-college'], dtype=object), array(['Divorced', 'Married', 'Separated', 'Single', 'Widowed'],\n",
      "      dtype=object), array(['Blue-Collar', 'Other/Unknown', 'Professional', 'Sales', 'Service',\n",
      "       'White-Collar'], dtype=object), array(['Other', 'White'], dtype=object), array(['Female', 'Male'], dtype=object)]\n",
      "X shape:  torch.Size([32561, 29])\n",
      "\n",
      "  | Name        | Type              | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------\n",
      "0 | val_acc     | Accuracy          | 0      | ?        | ?        \n",
      "1 | model       | Sequential        | 2.1 K  | [1, 29]  | [1, 1]   \n",
      "2 | sensitivity | SensitivityMetric | 0      | ?        | ?        \n",
      "-------------------------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff1c808e6324a5d9c9eee2792f9a580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/step_result.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n",
      "Global seed set to 31\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1a96940b9c49b2b7142347811f2ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba44efe17c04117a2dd8169bbf1ede0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name        | Type              | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------\n",
      "0 | val_acc     | Accuracy          | 0      | ?        | ?        \n",
      "1 | model       | Sequential        | 2.1 K  | [1, 29]  | [1, 1]   \n",
      "2 | sensitivity | SensitivityMetric | 0      | ?        | ?        \n",
      "-------------------------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Be aware that when using ``resume_from_checkpoint``, callbacks used to create the checkpoint need to be provided. Please, add the following callbacks: [<class 'pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint'>]. \n",
      "  warnings.warn(*args, **kwargs)\n",
      "Restored states from the checkpoint file at ../log/debug/version_2/checkpoints/epoch=0-step=178.ckpt\n",
      "\n",
      "x_cont: torch.Size([32561, 2]), x_cat: torch.Size([32561, 27])\n",
      "categories: [array(['Government', 'Other/Unknown', 'Private', 'Self-Employed'],\n",
      "      dtype=object), array(['Assoc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n",
      "       'Prof-school', 'School', 'Some-college'], dtype=object), array(['Divorced', 'Married', 'Separated', 'Single', 'Widowed'],\n",
      "      dtype=object), array(['Blue-Collar', 'Other/Unknown', 'Professional', 'Sales', 'Service',\n",
      "       'White-Collar'], dtype=object), array(['Other', 'White'], dtype=object), array(['Female', 'Male'], dtype=object)]\n",
      "X shape:  torch.Size([32561, 29])\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad715c0d649b4679917fda8c32339d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_config = load_configs('assets/configs/trainer.json')\n",
    "m_config = load_configs('assets/configs/adult.json')\n",
    "model = BaselinePredictiveModel(m_config)\n",
    "model_trainer = ModelTrainer(\n",
    "    model, t_config\n",
    ")\n",
    "model_trainer.fit()\n",
    "path = model_trainer.save_best_model(Path('.'))\n",
    "model_trainer.load_trained_model(str(path))\n",
    "!rm *.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CF Generator\n",
    "- local explainer\n",
    "- global explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CFGeneratorBase(ABC):\n",
    "    results = {\n",
    "        \"x\": None, \"cf\": None, \"y\": None, \"y_hat\": None, \"cf_y\": None, \"cf_y_hat\": None,\n",
    "        \"sensitivity\": None, \"total_time\": None, \"avg_time\": None, \"cf_algo\": None, \"cat_idx\": None\n",
    "    }\n",
    "\n",
    "    def __init__(self, cf_algo: ExplainerBase,\n",
    "            pred_model: BaselinePredictiveModel, configs: Dict[str, Any] = {}):\n",
    "        self.configs = configs\n",
    "        self.pred_model = pred_model\n",
    "        self.pred_model.freeze()\n",
    "\n",
    "        self.cf_algo = cf_algo\n",
    "        self.results.update({\"cf_algo\": type(cf_algo).__name__})\n",
    "        self.dataset = pred_model.test_dataset\n",
    "        self.sensitivity = pred_model.sensitivity\n",
    "\n",
    "    def generate(self, dataset: Optional[TensorDataset]=None, test_size: Optional[int] = None, debug: bool = False):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local CF Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LocalCFGenerator(CFGeneratorBase):\n",
    "    def __init__(self, cf_algo: LocalExplainerBase,\n",
    "            pred_model: BaselinePredictiveModel, configs: Dict[str, Any] = {}):\n",
    "        super().__init__(cf_algo, pred_model, configs)\n",
    "        # define cf_algo\n",
    "        if not issubclass(type(cf_algo), LocalExplainerBase):\n",
    "            raise ValueError(f\"cf_algo should be an instance of `{LocalExplainerBase}`, but got `{type(cf_algo)}`. \")\n",
    "        CFExplainer = type(cf_algo)\n",
    "        pred_fn = pred_model.forward\n",
    "        cat_normalizer = pred_model.cat_normalizer\n",
    "        self.cf_algo = CFExplainer(pred_fn, cat_normalizer, configs)\n",
    "\n",
    "        self.is_parallel = configs['is_parallel'] if 'is_parallel' in configs else True\n",
    "\n",
    "    def gen_step(self, x):\n",
    "        x = x.reshape(1, -1)\n",
    "        cf = self.cf_algo.generate_cf(x)\n",
    "        return x, cf\n",
    "\n",
    "    def iterative_generate(self, size: int, dataset: TensorDataset):\n",
    "        result = []\n",
    "        start_time = time.time()\n",
    "        for ix, (x, y) in enumerate(tqdm(dataset)):\n",
    "            if ix < size:\n",
    "                x, cf = self.gen_step(x)\n",
    "                result.append((x, cf))\n",
    "        total_time = time.time() - start_time\n",
    "        avg_time = total_time / size\n",
    "        return result, {'total_time': total_time, 'avg_time': avg_time}\n",
    "\n",
    "    def __unpack_x_cf(self, result: List[torch.Tensor]):\n",
    "        X = torch.rand((len(result), result[0][0].size(-1)))\n",
    "        cf_algo = X.clone()\n",
    "\n",
    "        for ix, (x, cf) in enumerate(result):\n",
    "            X[ix, :] = x\n",
    "            cf_algo[ix, :] = cf\n",
    "        return X, cf_algo\n",
    "\n",
    "    def generate(self, dataset: Optional[TensorDataset] = None, test_size: Optional[int] = None, debug: bool = False):\n",
    "        if dataset is None:\n",
    "            dataset = self.pred_model.test_dataset\n",
    "        if test_size is None:\n",
    "            size = len(dataset) if not debug else 3\n",
    "        else:\n",
    "            size = test_size\n",
    "\n",
    "        result = []\n",
    "\n",
    "        if self.is_parallel:\n",
    "            print(f\"generating {size} cfs in parallel...\")\n",
    "            result = Parallel(n_jobs=-1, max_nbytes=None, verbose=False)(\n",
    "                delayed(self.gen_step) (x=x)\n",
    "                for ix, (x, y) in enumerate(tqdm(dataset)) if ix < size\n",
    "            )\n",
    "            print(f\"evaluating speed by generating 50 cfs...\")\n",
    "            _, time = self.iterative_generate(50, dataset)\n",
    "        else:\n",
    "            print(f\"generating {size} cfs...\")\n",
    "            result, time = self.iterative_generate(size, dataset)\n",
    "\n",
    "        self.results.update(time)\n",
    "\n",
    "        x, cf = self.__unpack_x_cf(result)\n",
    "        _, y = dataset[:]\n",
    "        y = y[:size]\n",
    "        y_hat = self.pred_model.predict(x)\n",
    "        cf_y = flip_binary(y_hat)\n",
    "        cf_y_hat = self.pred_model.predict(cf)\n",
    "        sensitivity = self.pred_model.sensitivity\n",
    "\n",
    "        self.results.update({'x': x, 'cf': cf, 'y': y, 'y_hat': y_hat, 'cf_y': cf_y, 'cf_y_hat': cf_y_hat})\n",
    "        self.results.update({'sensitivity': sensitivity(x, cf, cf_y).item(), 'cat_idx': sensitivity.cat_idx})\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ff10345648d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocal_explainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalCFGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVanillaCF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'is_parallel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_explainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "local_explainer = LocalCFGenerator(VanillaCF(model.predict), model, {'is_parallel': False})\n",
    "results = local_explainer.generate(debug=True)\n",
    "\n",
    "def check_validity(r: Dict[str, Any]):\n",
    "    for k in r.keys():\n",
    "        if r[k] is None:\n",
    "            assert False, f\"{k} is None in self.results\"\n",
    "check_validity(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global CF Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# a temp workaround\n",
    "def is_predictive_model(model: BaseModule):\n",
    "    return callable(getattr(model, \"predict\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GlobalCFGenerator(CFGeneratorBase):\n",
    "    def __init__(self, cf_algo: GlobalExplainerBase,\n",
    "            pred_model: Optional[BaselinePredictiveModel] = None, configs: Dict[str, Any] = {}) -> None:\n",
    "        if not issubclass(type(cf_algo), GlobalExplainerBase):\n",
    "            raise ValueError(f\"cf_algo should be an instance of `{GlobalCFGenerator}`, but got `{type(cf_algo)}`\")\n",
    "        if not is_predictive_model(cf_algo) and pred_model is None:\n",
    "            raise ValueError(f\"pred_model should be passed when cf_algo is {type(cf_algo)}.\")\n",
    "        if is_predictive_model(cf_algo):\n",
    "            pred_model = cf_algo\n",
    "        super().__init__(cf_algo, pred_model, configs)\n",
    "\n",
    "    def generate(self, dataset: Optional[TensorDataset]=None, test_size: Optional[int] = None, debug: bool = False):\n",
    "        if dataset is None:\n",
    "            dataset = self.pred_model.test_dataset\n",
    "        if test_size is None:\n",
    "            size = len(dataset) if not debug else 3\n",
    "        else:\n",
    "            size = test_size\n",
    "        x, y = dataset[:]\n",
    "\n",
    "        print(f\"generating {len(dataset)} cfs...\")\n",
    "        cf = self.cf_algo.generate_cf(x)\n",
    "\n",
    "        print(f\"evaluating speed...\")\n",
    "        start_time = time.time()\n",
    "        for i, (sample, _) in enumerate(dataset):\n",
    "            if i < size:\n",
    "                self.cf_algo.generate_cf(sample.reshape(1, -1))\n",
    "        total_time = time.time() - start_time\n",
    "        avg_time = total_time / size\n",
    "\n",
    "        y_hat = self.pred_model.predict(x)\n",
    "        cf_y = flip_binary(y_hat)\n",
    "        cf_y_hat = self.pred_model.predict(cf)\n",
    "        sensitivity = self.pred_model.sensitivity\n",
    "\n",
    "        self.results.update({'x': x, 'cf': cf, 'y': y, 'y_hat': y_hat, 'cf_y': cf_y, 'cf_y_hat': cf_y_hat})\n",
    "        self.results.update({'sensitivity': sensitivity(x, cf, cf_y).item(), 'cat_idx': sensitivity.cat_idx})\n",
    "        self.results.update({'total_time': total_time, 'avg_time': avg_time})\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Evaluator(object):\n",
    "    def __init__(self, configs: Dict[str, Any]={}):\n",
    "        self.is_logging: bool = configs['is_logging'] if 'is_logging' in configs.keys() else True\n",
    "\n",
    "    def eval(self, results: Dict[str, Any], dir_path: Path):\n",
    "        if not dir_path.exists():\n",
    "            raise ValueError(f\"{dir_path} does not exist.\")\n",
    "        csv_path = dir_path / Path('metrics.csv')\n",
    "\n",
    "        metrics = ['cat_proximity', 'cont_proximity', 'validity', 'sensitivity', 'time', 'pred_accuracy', 'proximity']\n",
    "        # ['sparsity', 'diffs', 'total_num']\n",
    "\n",
    "        if csv_path.exists():\n",
    "            r = pd.read_csv(csv_path, index_col=0).to_dict()\n",
    "            for metric in metrics:\n",
    "                if metric not in r.keys():\n",
    "                    r[metric] = dict()\n",
    "        else:\n",
    "            r = {metric:{} for metric in metrics}\n",
    "\n",
    "        x, cf, y, y_hat, cf_y, cf_y_hat = results['x'], results['cf'], results['y'], \\\n",
    "            results['y_hat'], results['cf_y'], results['cf_y_hat']\n",
    "        cat_idx, cf_name = results['cat_idx'], results['cf_algo']\n",
    "\n",
    "        r['cont_proximity'][cf_name] = proximity(x[:, :cat_idx], cf[:, :cat_idx]).item()\n",
    "        r['cat_proximity'][cf_name] = proximity(x[:, cat_idx:], cf[:, cat_idx:]).item()\n",
    "        r['proximity'][cf_name] = r['cont_proximity'][cf_name] + r['cat_proximity'][cf_name]\n",
    "        r['validity'][cf_name] = accuracy(cf_y.int(), cf_y_hat.int()).item()\n",
    "        r['sensitivity'][cf_name] = results['sensitivity']\n",
    "        r['time'][cf_name] = results['avg_time']\n",
    "        r['pred_accuracy'][cf_name] = accuracy(y.int(), y_hat.int()).item()\n",
    "\n",
    "        final_result_df = pd.DataFrame.from_dict(r)\n",
    "        print(tabulate(final_result_df.astype(\"float16\"), headers = 'keys', tablefmt = 'pretty'))\n",
    "        if self.is_logging:\n",
    "            final_result_df.to_csv(csv_path)\n",
    "            torch.save(results, dir_path / f\"{cf_name}_results.pt\")\n",
    "            print(\"Results has been saved!\")\n",
    "        return final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+------------------+------------+---------------+------------+---------+-------------+---------+-----------------+-------------+\n",
      "|           |   cat_proximity |   cont_proximity |   validity |   sensitivity |   sparsity |   diffs |   total_num |    time |   pred_accuracy |   proximity |\n",
      "|-----------+-----------------+------------------+------------+---------------+------------+---------+-------------+---------+-----------------+-------------|\n",
      "| VanillaCF |         8.66667 |          2.18143 |   0.333333 |          -inf |        nan |     nan |         nan | 1.29778 |        0.666667 |     10.8481 |\n",
      "+-----------+-----------------+------------------+------------+---------------+------------+---------+-------------+---------+-----------------+-------------+\n",
      "Results has been saved!\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "evaluator.eval(results, Path('.'))\n",
    "!rm \"metrics.csv\"\n",
    "!rm *.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Experiment(object):\n",
    "    def __init__(self, explainers: List[ExplainerBase],\n",
    "            m_configs: List[Dict[str, Any]], t_configs: Optional[Dict[str, Any]] = None, debug: bool = False):\n",
    "        self.explainers = explainers\n",
    "        self.m_configs = m_configs\n",
    "        self.use_pred_model = False # need a `BaselinePredictiveModel` or not\n",
    "        self.pred_model = None      # init a `BaselinePredictiveModel` if neccesary\n",
    "        if t_configs is None:\n",
    "            self.t_configs = load_configs(Path('assets/configs/trainer.json'))\n",
    "        else:\n",
    "            self.t_configs = t_configs\n",
    "        self.__check_explainers()\n",
    "        self.debug = debug\n",
    "\n",
    "        self.evaluator = Evaluator(configs={'is_logging': True})\n",
    "\n",
    "    def __is_type(self, instance):\n",
    "        return isinstance(type(instance), type) or isinstance(type(instance), ABCMeta)\n",
    "            \n",
    "    def __check_explainers(self):\n",
    "        for explainer in self.explainers: # explainer is already passed as a type\n",
    "            if self.__is_type(explainer):\n",
    "                explainer_type = deepcopy(explainer)\n",
    "                explainer = explainer_type(self.m_configs[0])\n",
    "            else:\n",
    "                explainer_type = type(explainer)\n",
    "            if not issubclass(explainer_type, ExplainerBase):\n",
    "                raise ValueError(f\"The explainer should be a subclass of `{ExplainerBase}`, but got `{explainer_type}`\")\n",
    "            if not (isinstance(explainer, CounterNetModel) or (issubclass(explainer_type, CFNetTrainingModule))):\n",
    "                self.use_pred_model = True\n",
    "\n",
    "    def __check_seeds(self, seeds: Optional[List[int]]):\n",
    "        try:\n",
    "            seeds = seeds if seeds is not None else [os.environ.get(\"PL_GLOBAL_SEED\")]\n",
    "        except (TypeError, ValueError):\n",
    "            seed_everything(31); seeds = [31]\n",
    "        return seeds\n",
    "\n",
    "    def __make_dir(self, dataset_name: str, seed: List[int]):\n",
    "        dir_path = Path(f'assets/results/{dataset_name}/seed-{seed}/')\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        return dir_path\n",
    "\n",
    "    def explainer_step(self, explainer: ExplainerBase, pred_model: BaselinePredictiveModel,\n",
    "            m_config: Dict[str, Any], dir_path: Path):\n",
    "        if not self.__is_type(explainer):\n",
    "            CFExplainer = type(explainer)\n",
    "        else:\n",
    "            CFExplainer = explainer\n",
    "        if issubclass(CFExplainer, GlobalExplainerBase):\n",
    "            if issubclass(CFExplainer, CounterNetModel):\n",
    "                model = CFExplainer(m_config)\n",
    "            else: # need a predive model otherwise\n",
    "                model = CFExplainer(m_config, pred_model)\n",
    "            logger_name = f\"{CFExplainer.__name__.lower()}/{m_config['dataset_name']}\"\n",
    "            cfnet_trainer = ModelTrainer(model, self.t_configs, logger_name=logger_name)\n",
    "            cfnet_trainer.fit()\n",
    "            cfnet_trainer.save_best_model(dir_path)\n",
    "            cf_generator = GlobalCFGenerator(model)\n",
    "        else:\n",
    "            print(f\"Generating local explanation for {CFExplainer}\")\n",
    "            cf_generator = LocalCFGenerator(CFExplainer(pred_model.predict), pred_model)\n",
    "        results = cf_generator.generate(debug=self.debug)\n",
    "        self.evaluator.eval(results, dir_path)\n",
    "\n",
    "    def experiment_step(self, m_config, seed: List[int]):\n",
    "        # train a baseline predictive model\n",
    "        if self.use_pred_model:\n",
    "            print(\"training predictive model...\")\n",
    "            pred_model_trainer = ModelTrainer(\n",
    "                BaselinePredictiveModel(m_config), self.t_configs, logger_name=\"pred_model\")\n",
    "            pred_model = pred_model_trainer.fit()\n",
    "        else:\n",
    "            pred_model = None\n",
    "\n",
    "        dataset_name = m_config['dataset_name']\n",
    "        # logging dir\n",
    "        dir_path = self.__make_dir(dataset_name, seed)\n",
    "        \n",
    "        for explainer in self.explainers:\n",
    "            self.explainer_step(explainer, pred_model, m_config, dir_path)\n",
    "\n",
    "    def run(self, seeds: Optional[List[int]] = None):\n",
    "        seeds = self.__check_seeds(seeds)\n",
    "        for seed in seeds:\n",
    "            seed_everything(seed, workers=True)\n",
    "            for m_config in self.m_configs:\n",
    "                self.experiment_step(m_config, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 31\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name        | Type              | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------\n",
      "0 | val_acc     | Accuracy          | 0      | ?        | ?        \n",
      "1 | model       | Sequential        | 2.1 K  | [1, 29]  | [1, 1]   \n",
      "2 | sensitivity | SensitivityMetric | 0      | ?        | ?        \n",
      "-------------------------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "x_cont: torch.Size([32561, 2]), x_cat: torch.Size([32561, 27]), X shape: torch.Size([32561, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfa3534dc0d434ca2842687f404d04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/step_result.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n",
      "Global seed set to 31\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a16f9567581482a9e8c34fcebb00bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a965874d6f4d8fb1c08deffbfbf83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() missing 2 required positional arguments: 'bases' and 'namespace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c68a0a8450c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCounterNetModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVanillaCF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'assets/configs/adult.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-170ceeada96e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, seeds)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-170ceeada96e>\u001b[0m in \u001b[0;36mexperiment_step\u001b[0;34m(self, m_config, seed)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mpred_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_model_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-170ceeada96e>\u001b[0m in \u001b[0;36mexplainer_step\u001b[0;34m(self, explainer, pred_model, m_config, dir_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mcf_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalCFGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mcf_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalCFGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() missing 2 required positional arguments: 'bases' and 'namespace'"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(explainers = [CounterNetModel, VanillaCF], \n",
    "    m_configs=[load_configs(Path('assets/configs/adult.json'))], debug=True)\n",
    "experiment.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
