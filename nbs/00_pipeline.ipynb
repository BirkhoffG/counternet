{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 31\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from counternet.import_essentials import *\n",
    "from counternet.utils.all import *\n",
    "from counternet.training_module import BaseModule\n",
    "from counternet.model import BaselinePredictiveModel, CounterNetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_trained_model(module: BaseModule, checkpoint_path: str, gpus : int = 0) -> BaseModule:\n",
    "    # assuming checkpoint_path = f\"{dict_path}/epoch={n_epoch}-step={step}.ckpt\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f'{checkpoint_path} is not found.')\n",
    "\n",
    "    n_iter = int(checkpoint_path.split(\"-\")[0].split(\"=\")[-1]) + 1\n",
    "    model = module.load_from_checkpoint(checkpoint_path)\n",
    "    tmp_trainer = pl.Trainer(\n",
    "        max_epochs=n_iter, resume_from_checkpoint=checkpoint_path, num_sanity_val_steps=0, gpus=gpus,\n",
    "        logger=False, checkpoint_callback=False\n",
    "    )\n",
    "    tmp_trainer.fit(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModelTrainer(object):\n",
    "    def __init__(self,\n",
    "                 model: BaseModule,\n",
    "                 t_configs: Dict[str, Any],\n",
    "                 callbacks: Optional[List[Callback]] = None,\n",
    "                 description: Optional[str] = None,\n",
    "                 debug: Optional[bool] = False,\n",
    "                 logger: Optional[LightningLoggerBase] = None,\n",
    "                 logger_name: str = \"debug\"):\n",
    "\n",
    "        if logger is None:\n",
    "            logger = pl_loggers.TestTubeLogger(\n",
    "                Path('../log/'),\n",
    "                name=logger_name,\n",
    "                description=description,\n",
    "                debug=debug,\n",
    "                log_graph=True\n",
    "            )\n",
    "\n",
    "        # model checkpoint\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='val/val_loss',\n",
    "            save_top_k=3,\n",
    "            mode='min'\n",
    "        )\n",
    "\n",
    "        # define callbacks\n",
    "        if callbacks is None:\n",
    "            callbacks = [checkpoint_callback]\n",
    "        elif self._has_no_model_checkpoint(callbacks):\n",
    "            callbacks += [checkpoint_callback]\n",
    "\n",
    "        self.trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            callbacks=callbacks,\n",
    "            **t_configs\n",
    "        )\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def _has_no_model_checkpoint(self, callbacks: List[Callback]) -> bool:\n",
    "        for callback in callbacks:\n",
    "            if isinstance(callback, ModelCheckpoint):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def fit(self, is_parallel=False):\n",
    "        if is_parallel:\n",
    "            logging.warning(\n",
    "                f\"parallel version has not been implemented\\nUsing the single process training...\")\n",
    "        self.trainer.fit(self.model)\n",
    "\n",
    "        return dict(\n",
    "            trainer=self.trainer,\n",
    "            module=self.model\n",
    "        )\n",
    "\n",
    "    def load_trained_model(self, checkpoint_path: str, gpus: int = 0) -> BaseModule:\n",
    "        self.model = load_trained_model(\n",
    "            self.model, checkpoint_path=checkpoint_path, gpus=gpus)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name        | Type              | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------\n",
      "0 | val_acc     | Accuracy          | 0      | ?        | ?        \n",
      "1 | model       | Sequential        | 2.1 K  | [1, 29]  | [1, 1]   \n",
      "2 | sensitivity | SensitivityMetric | 0      | ?        | ?        \n",
      "-------------------------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "train (tensor([[0.4184, 0.4490, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
      "        [0.3163, 0.3980, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
      "        [0.3469, 0.3980, 0.0000,  ..., 1.0000, 1.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.3878, 0.3980, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.3571, 0.3469, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
      "        [0.1939, 0.4796, 0.0000,  ..., 1.0000, 0.0000, 1.0000]]), tensor([1., 0., 1.,  ..., 0., 1., 0.]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d6a572d1bf4d0385d38a62a9dc5d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/step_result.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n",
      "Global seed set to 31\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5cb5c32a0745a3895e97de91ad46c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c18566866d4460398b14774b93b7519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'trainer': <pytorch_lightning.trainer.trainer.Trainer at 0x7f45f405a5e0>,\n",
       " 'module': BaselinePredictiveModel(\n",
       "   (val_acc): Accuracy()\n",
       "   (model): Sequential(\n",
       "     (0): MultilayerPerception(\n",
       "       (model): Sequential(\n",
       "         (0): LinearBlock(\n",
       "           (block): Sequential(\n",
       "             (0): Linear(in_features=29, out_features=50, bias=True)\n",
       "             (1): LeakyReLU(negative_slope=0.01)\n",
       "             (2): Dropout(p=0.3, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (1): LinearBlock(\n",
       "           (block): Sequential(\n",
       "             (0): Linear(in_features=50, out_features=10, bias=True)\n",
       "             (1): LeakyReLU(negative_slope=0.01)\n",
       "             (2): Dropout(p=0.3, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): MultilayerPerception(\n",
       "       (model): Sequential(\n",
       "         (0): LinearBlock(\n",
       "           (block): Sequential(\n",
       "             (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "             (1): LeakyReLU(negative_slope=0.01)\n",
       "             (2): Dropout(p=0.3, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): Linear(in_features=10, out_features=1, bias=True)\n",
       "   )\n",
       "   (sensitivity): SensitivityMetric()\n",
       " )}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_config = load_json('assets/configs/trainer.json')\n",
    "m_config = load_json('assets/configs/adult.json')\n",
    "model = BaselinePredictiveModel(m_config)\n",
    "model_trainer = ModelTrainer(\n",
    "    model, t_config\n",
    ")\n",
    "model_trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CF Generator\n",
    "- local explainer\n",
    "- global explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
