{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 31\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BaseModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-373ba5fd56e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcounternet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_essentials\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcounternet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcounternet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFNetTrainingModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcounternet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaselinePredictiveModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounterNetModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/counternet/counternet/utils/all.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/counternet/counternet/utils/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Comes from 00_pipeline.ipynb, cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_predictive_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseModule' is not defined"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from torchmetrics.classification import accuracy\n",
    "from counternet.import_essentials import *\n",
    "from counternet.utils import *\n",
    "from counternet.training_module import BaseModule, CFNetTrainingModule\n",
    "from counternet.model import BaselinePredictiveModel, CounterNetModel\n",
    "from counternet.cf_explainer import ExplainerBase, LocalExplainerBase, GlobalExplainerBase\n",
    "from counternet.evaluation import SensitivityMetric, proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_trained_model(module: BaseModule, checkpoint_path: str, gpus : int = 0) -> BaseModule:\n",
    "    # assuming checkpoint_path = f\"{dict_path}/epoch={n_epoch}-step={step}.ckpt\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f'{checkpoint_path} is not found.')\n",
    "\n",
    "    n_iter = int(checkpoint_path.split(\"-\")[0].split(\"=\")[-1]) + 1\n",
    "    model = module.load_from_checkpoint(checkpoint_path)\n",
    "    tmp_trainer = pl.Trainer(\n",
    "        max_epochs=n_iter, resume_from_checkpoint=checkpoint_path, num_sanity_val_steps=0, gpus=gpus,\n",
    "        logger=False, checkpoint_callback=False\n",
    "    )\n",
    "    tmp_trainer.fit(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModelTrainer(object):\n",
    "    def __init__(self,\n",
    "                 model: BaseModule,\n",
    "                 t_configs: Dict[str, Any],\n",
    "                 callbacks: Optional[List[Callback]] = None,\n",
    "                 description: Optional[str] = None,\n",
    "                 debug: Optional[bool] = False,\n",
    "                 logger: Optional[LightningLoggerBase] = None,\n",
    "                 logger_name: str = \"debug\"):\n",
    "\n",
    "        if logger is None:\n",
    "            logger = pl_loggers.TestTubeLogger(\n",
    "                Path('../log/'), name=logger_name,\n",
    "                description=description, debug=debug, log_graph=True\n",
    "            )\n",
    "\n",
    "        # model checkpoint\n",
    "        self.checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='val/val_loss', save_top_k=3, mode='min'\n",
    "        )\n",
    "\n",
    "        # define callbacks\n",
    "        if callbacks is None:\n",
    "            callbacks = [self.checkpoint_callback]\n",
    "        elif self._has_no_model_checkpoint(callbacks):\n",
    "            callbacks += [self.checkpoint_callback]\n",
    "\n",
    "        self.trainer = pl.Trainer(logger=logger, callbacks=callbacks, **t_configs)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def _has_no_model_checkpoint(self, callbacks: List[Callback]) -> bool:\n",
    "        for callback in callbacks:\n",
    "            if isinstance(callback, ModelCheckpoint):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def fit(self, is_parallel=False):\n",
    "        if is_parallel:\n",
    "            logging.warning(\n",
    "                f\"parallel version has not been implemented\\nUsing the single process training...\")\n",
    "        self.trainer.fit(self.model)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def save_best_model(self, dir_path: Path):\n",
    "        if not dir_path.is_dir():\n",
    "            raise ValueError(f\"'{dir_path}' is not a directory\")\n",
    "        best_model_path = Path(self.checkpoint_callback.best_model_path)\n",
    "        shutil.copy(best_model_path, dir_path)\n",
    "\n",
    "    def load_trained_model(self, checkpoint_path: str, gpus: int = 0) -> BaseModule:\n",
    "        self.model = load_trained_model(\n",
    "            self.model, checkpoint_path=checkpoint_path, gpus=gpus)\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name        | Type              | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------------------\n",
      "0 | val_acc     | Accuracy          | 0      | ?        | ?        \n",
      "1 | model       | Sequential        | 2.1 K  | [1, 29]  | [1, 1]   \n",
      "2 | sensitivity | SensitivityMetric | 0      | ?        | ?        \n",
      "-------------------------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "x_cont: torch.Size([32561, 2]), x_cat: torch.Size([32561, 27])\n",
      "categories: [array(['Government', 'Other/Unknown', 'Private', 'Self-Employed'],\n",
      "      dtype=object), array(['Assoc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n",
      "       'Prof-school', 'School', 'Some-college'], dtype=object), array(['Divorced', 'Married', 'Separated', 'Single', 'Widowed'],\n",
      "      dtype=object), array(['Blue-Collar', 'Other/Unknown', 'Professional', 'Sales', 'Service',\n",
      "       'White-Collar'], dtype=object), array(['Other', 'White'], dtype=object), array(['Female', 'Male'], dtype=object)]\n",
      "X shape:  torch.Size([32561, 29])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e48a099d4646ada763831a6eebb531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/step_result.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n",
      "Global seed set to 31\n",
      "/home/birk/software/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e7b9e1c9ba46028f6d61c2fd76b1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ea18e4716f472c98baab5b65266b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t_config = load_json('assets/configs/trainer.json')\n",
    "m_config = load_json('assets/configs/adult.json')\n",
    "model = BaselinePredictiveModel(m_config)\n",
    "model_trainer = ModelTrainer(\n",
    "    model, t_config\n",
    ")\n",
    "model_trainer.fit()\n",
    "model_trainer.save_best_model(Path('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CF Generator\n",
    "- local explainer\n",
    "- global explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CFGeneratorBase(ABC):\n",
    "    results = {\n",
    "        \"x\": None, \"cf\": None, \"y\": None, \"y_hat\": None, \"cf_y\": None, \"cf_y_hat\": None,\n",
    "        \"sensitivity\": None, \"total_time\": None, \"avg_time\": None, \"cf_algo\": None, \"cat_idx\": None\n",
    "    }\n",
    "\n",
    "    def __init__(self, cf_algo: ExplainerBase,\n",
    "            pred_model: BaselinePredictiveModel, configs: Dict[str, Any] = {}):\n",
    "        self.configs = configs\n",
    "        self.pred_model = pred_model\n",
    "        self.pred_model.eval()\n",
    "\n",
    "        self.cf_algo = cf_algo\n",
    "        self.results.update({\"cf_algo\": type(cf_algo).__name__})\n",
    "        self.dataset = pred_model.test_dataset\n",
    "        self.sensitivity = pred_model.sensitivity\n",
    "\n",
    "    def generate(self, dataset: Optional[TensorDataset]=None):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local CF Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LocalCFGenerator(CFGeneratorBase):\n",
    "    def __init__(self, cf_algo: LocalExplainerBase,\n",
    "            pred_model: BaselinePredictiveModel, configs: Dict[str, Any] = {}):\n",
    "        super().__init__(cf_algo, pred_model, configs)\n",
    "        # define cf_algo\n",
    "        if not issubclass(type(cf_algo), LocalExplainerBase):\n",
    "            raise ValueError(\"cf_algo should be an instance of `LocalExplainerBase`\")\n",
    "        CFExplainer = type(cf_algo)\n",
    "        pred_fn = pred_model.forward\n",
    "        cat_normalizer = pred_model.cat_normalizer\n",
    "        self.cf_algo = CFExplainer(pred_fn, cat_normalizer, configs)\n",
    "\n",
    "        self.is_parallel = configs['is_parallel'] if 'is_parallel' in configs else True\n",
    "\n",
    "    def __gen_step(self, ix, x, y):\n",
    "        x = x.reshape(1, -1)\n",
    "        cf = self.cf_algo.generate_cf(x)\n",
    "        return x, cf\n",
    "\n",
    "    def iterative_generate(self, size: int, dataset: TensorDataset):\n",
    "        result = []\n",
    "        start_time = time.time()\n",
    "        for ix, (x, y) in enumerate(tqdm(dataset)):\n",
    "            if ix < size:\n",
    "                x, cf = self.__gen_step(ix, x, y)\n",
    "                result.append((x, cf))\n",
    "        total_time = time.time() - start_time\n",
    "        avg_time = total_time / size\n",
    "        return result, {'total_time': total_time, 'avg_time': avg_time}\n",
    "\n",
    "    def __unpack_x_cf(self, result: List[torch.Tensor]):\n",
    "        X = torch.rand((len(result), result[0][0].size(-1)))\n",
    "        cf_algo = X.clone()\n",
    "\n",
    "        for ix, (x, cf) in enumerate(result):\n",
    "            X[ix, :] = x\n",
    "            cf_algo[ix, :] = cf\n",
    "        return X, cf_algo\n",
    "\n",
    "    def generate(self, dataset: Optional[TensorDataset]=None, debug: bool = False):\n",
    "        if dataset is None:\n",
    "            dataset = self.pred_model.test_dataset\n",
    "        size = len(dataset) if not debug else 1\n",
    "\n",
    "        result = []\n",
    "\n",
    "        if self.is_parallel:\n",
    "            print(f\"generating {size} cfs in parallel...\")\n",
    "            result = Parallel(n_jobs=-1, max_nbytes=None, verbose=False)(\n",
    "                delayed(self.__gen_step) (ix=ix, x=x, y=y)\n",
    "                for ix, (x, y) in enumerate(tqdm(dataset)) if ix < size\n",
    "            )\n",
    "            print(f\"evaluating speed by generating 50 cfs...\")\n",
    "            _, time = self.iterative_generate(50, dataset)\n",
    "        else:\n",
    "            print(f\"generating {size} cfs...\")\n",
    "            result, time = self.iterative_generate(size, dataset)\n",
    "\n",
    "        self.results.update(time)\n",
    "\n",
    "        x, cf = self.__unpack_x_cf(result)\n",
    "        _, y = dataset[:]\n",
    "        y_hat = self.pred_model.predict(x)\n",
    "        cf_y = flip_binary(y_hat)\n",
    "        cf_y_hat = self.pred_model.predict(cf)\n",
    "\n",
    "        self.results.update({'x': x, 'cf': cf, 'y': y, 'y_hat': y_hat, 'cf_y': cf_y, 'cf_y_hat': cf_y_hat})\n",
    "        self.results.update({'sensitivity': self.pred_model.sensitivity, 'cat_idx': self.pred_model.sensitivity.cat_idx})\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6513 [00:00<?, ?it/s]generating 1 cfs...\n",
      "100%|██████████| 6513/6513 [00:01<00:00, 4384.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0.3878, 0.3980, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
       "          0.0000, 1.0000]]),\n",
       " 'cf': tensor([[1.4207, 1.4595, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
       "          0.0000, 1.0000]], grad_fn=<CopySlices>),\n",
       " 'y': tensor([0., 1., 0.,  ..., 0., 0., 0.]),\n",
       " 'y_hat': tensor([0.], grad_fn=<RoundBackward>),\n",
       " 'cf_y': tensor([1.]),\n",
       " 'cf_y_hat': tensor([1.], grad_fn=<RoundBackward>),\n",
       " 'sensitivity': SensitivityMetric(),\n",
       " 'total_time': 1.4879868030548096,\n",
       " 'avg_time': 1.4879868030548096,\n",
       " 'cf_algo': 'VanillaCF'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from counternet.cf_explainer import VanillaCF\n",
    "\n",
    "local_explainer = LocalCFGenerator(VanillaCF(model.predict), model, {'is_parallel': False})\n",
    "result = local_explainer.generate(debug=True)\n",
    "\n",
    "def check_validity(r: Dict[str, Any]):\n",
    "    for k in r.keys():\n",
    "        if r[k] is None:\n",
    "            assert False, f\"{k} is None in self.results\"\n",
    "check_validity(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global CF Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export functional_utils\n",
    "def is_predictive_model(model: BaseModule):\n",
    "    return callable(getattr(model, \"predict\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GlobalCFGenerator(CFGeneratorBase):\n",
    "    def __init__(self, cf_algo: GlobalExplainerBase,\n",
    "            pred_model: Optional[BaselinePredictiveModel] = None, configs: Dict[str, Any] = {}) -> None:\n",
    "        if not isinstance(cf_algo, GlobalCFGenerator):\n",
    "            raise ValueError(\"cf_algo should be an instance of `GlobalCFGenerator`\")\n",
    "        if not is_predictive_model(cf_algo) and pred_model is None:\n",
    "            raise ValueError(f\"pred_model should be passed when cf_algo is {type(cf_algo)}.\")\n",
    "        if is_predictive_model(cf_algo):\n",
    "            pred_model = cf_algo\n",
    "        super().__init__(cf_algo, pred_model, configs)\n",
    "\n",
    "    def generate(self, dataset: Optional[TensorDataset]=None):\n",
    "        if dataset is None:\n",
    "            dataset = self.pred_model.test_dataset\n",
    "        x, y = dataset[:]\n",
    "\n",
    "        print(f\"generating {len(dataset)} cfs...\")\n",
    "        cf = self.cf_algo.generate_cf(x)\n",
    "\n",
    "        print(f\"evaluating speed...\")\n",
    "        start_time = time.time()\n",
    "        for x, _ in dataset:\n",
    "            x = x.reshape(1, -1)\n",
    "            self.cf_algo.generate_cf(x)\n",
    "        total_time = time.time() - start_time\n",
    "        avg_time = total_time / len(dataset)\n",
    "\n",
    "        y_hat = self.pred_model.predict(x)\n",
    "        cf_y = flip_binary(y_hat)\n",
    "        cf_y_hat = self.pred_model.predict(cf)\n",
    "\n",
    "        self.results.update({'x': x, 'cf': cf, 'y': y, 'y_hat': y_hat, 'cf_y': cf_y, 'cf_y_hat': cf_y_hat})\n",
    "        self.results.update({'sensitivity': self.pred_model.sensitivity, 'cat_idx': self.pred_model.sensitivity.cat_idx})\n",
    "        self.results.update({'total_time': total_time, 'avg_time': avg_time})\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Evaluator(object):\n",
    "    def __init__(self, configs: Dict[str, Any]={}):\n",
    "        self.is_logging: bool = configs['is_logging'] if 'is_logging' in configs.keys() else True\n",
    "\n",
    "    def eval(self, results: Dict[str, Any], dir_path: Path):\n",
    "        if not dir_path.exists():\n",
    "            raise ValueError(f\"{dir_path} does not exist.\")\n",
    "        csv_path = dir_path / Path('metrics.csv')\n",
    "\n",
    "        metrics = ['cat_proximity', 'cont_proximity', 'validity',\n",
    "                'sensitivity', 'sparsity', 'diffs', 'total_num', 'time', 'pred_accuracy', 'proximity']\n",
    "\n",
    "        if csv_path.exists():\n",
    "            r = pd.read_csv(csv_path, index_col=0).to_dict()\n",
    "            for metric in metrics:\n",
    "                if metric not in r.keys():\n",
    "                    r[metric] = dict()\n",
    "        else:\n",
    "            r = {metric for metric in metrics}\n",
    "\n",
    "        x, cf, y, y_hat, cf_y, cf_y_hat = results['x'], results['cf'], results['y'], \\\n",
    "            results['y_hat'], results['cf_y'], results['cf_y_hat']\n",
    "        cat_idx, cf_name = results['cat_idx'], results['cf_algo']\n",
    "\n",
    "        r['cont_proximity'][cf_name] = proximity(x[:, :cat_idx], cf[:, :cat_idx]).item()\n",
    "        r['cat_proximity'][cf_name] = proximity(x[:, cat_idx:], cf[:, cat_idx:]).item()\n",
    "        r['proximity'][cf_name] = r['cont_proximity'][cf_name] + r['cat_proximity'][cf_name]\n",
    "        r['validity'][cf_name] = accuracy(cf_y, cf_y_hat).item()\n",
    "        r['sensitivity'][cf_name] = results['sensitivity'].compute(x, cf, cf_y)\n",
    "        r['time'][cf_name] = results['avg_time']\n",
    "        r['pred_accuracy'][cf_name] = accuracy(y, y_hat).item()\n",
    "\n",
    "        final_result_df = pd.DataFrame.from_dict(r)\n",
    "        print(tabulate(final_result_df, headers = 'keys', tablefmt = 'psql'))\n",
    "        if self.is_logging:\n",
    "            final_result_df.to_csv(csv_path)\n",
    "            torch.save(results, dir_path)\n",
    "            print(\"Results has been saved!\")\n",
    "        return final_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Pipeline(object):\n",
    "    def __init__(self, explainers: List[ExplainerBase],\n",
    "            m_configs: List[Dict[str, Any]], t_configs: Optional[Dict[str, Any]] = None):\n",
    "        self.explainers = explainers\n",
    "        self.m_configs = m_configs\n",
    "        self.use_pred_model = False # need a `BaselinePredictiveModel` or not\n",
    "        self.pred_model = None      # init a `BaselinePredictiveModel` if neccesary\n",
    "        if t_configs is None:\n",
    "            self.t_configs = load_json(Path('assets/configs/trainer.json'))\n",
    "        else:\n",
    "            self.t_configs = t_configs\n",
    "        self.__check_explainers()\n",
    "\n",
    "        self.evaluator = Evaluator(configs={'is_logging': True})\n",
    "\n",
    "    def __check_explainers(self):\n",
    "        for explainer in self.explainers:\n",
    "            if not issubclass(type(explainer), ExplainerBase):\n",
    "                raise ValueError(\"The explainer should be a subclass of `ExplainerBase`\")\n",
    "            if not isinstance(explainer, CFNetTrainingModule):\n",
    "                self.use_pred_model = True\n",
    "\n",
    "    def __check_seeds(self, seeds: Optional[List[int]]):\n",
    "        try:\n",
    "            seeds = seeds if seeds is not None else [os.environ.get(\"PL_GLOBAL_SEED\")]\n",
    "        except (TypeError, ValueError):\n",
    "            seed_everything(31); seeds = [31]\n",
    "        return seeds\n",
    "\n",
    "    def __make_dir(self, dataset_name: str, seed: List[int]):\n",
    "        dir_path = Path(f'assets/results/{dataset_name}/seed-{seed}/')\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        return dir_path\n",
    "\n",
    "    def explainer_step(self, explainer: ExplainerBase, pred_model: BaselinePredictiveModel,\n",
    "            m_config: Dict[str, Any], dir_path: Path):\n",
    "        CFExplainer = type(explainer)\n",
    "        if issubclass(CFExplainer, GlobalExplainerBase):\n",
    "            CFExplainer = type(explainer)\n",
    "            if issubclass(CFExplainer, CounterNetModel):\n",
    "                model = CFExplainer(m_config)\n",
    "            else: # need a predive model otherwise\n",
    "                model = CFExplainer(m_config, pred_model)\n",
    "            cfnet_trainer = ModelTrainer(model, self.t_configs)\n",
    "            cfnet_trainer.fit()\n",
    "            cfnet_trainer.save_best_model(dir_path)\n",
    "            cf_generator = GlobalCFGenerator(model)\n",
    "        else:\n",
    "            cf_generator = LocalCFGenerator(CFExplainer(pred_model.predict), pred_model)\n",
    "        results = cf_generator.generate()\n",
    "        self.evaluator.eval(results, dir_path)\n",
    "\n",
    "    def pipeline_step(self, m_config, seed: List[int]):\n",
    "        if self.use_pred_model:\n",
    "            pred_model = BaselinePredictiveModel(m_config)\n",
    "        dataset_name = m_config['dataset_name']\n",
    "        # logging dir\n",
    "        dir_path = self.__make_dir(dataset_name, seed)\n",
    "        # train a baseline predictive model\n",
    "        pred_model_trainer = ModelTrainer(pred_model, self.t_configs)\n",
    "        pred_model = pred_model_trainer.fit()\n",
    "        for explainer in self.explainers:\n",
    "            self.explainer_step(explainer, pred_model, m_config, dir_path)\n",
    "\n",
    "    def run(self, seeds: Optional[List[int]] = None):\n",
    "        seeds = self.__check_seeds(seeds)\n",
    "        for seed in seeds:\n",
    "            seed_everything(seed)\n",
    "            for m_config in self.m_configs:\n",
    "                self.pipeline_step(m_config, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestObj:\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"(val: {self.val})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(val: 1), (val: 2), (val: 3), (val: 4), (val: 5)]\n"
     ]
    }
   ],
   "source": [
    "obj_list = [TestObj(val) for val in [1, 2, 3, 4, 5]]\n",
    "print(obj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(val: 1), (val: 10), (val: 3), (val: 4), (val: 5)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, obj in enumerate(obj_list):\n",
    "    if i == 1:\n",
    "        obj.val = 10\n",
    "obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(seeds = [1, 2, 3, 4, 5], models = [CounterNetModel])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
