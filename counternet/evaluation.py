# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00a_evaluation.ipynb (unless otherwise specified).

__all__ = ['SensitivityMetric']

# Cell
from .import_essentials import *
from .utils.functional import *
from .utils.processing import *

# Comes from 02_counter_net.ipynb, cell
class SensitivityMetric(Metric):
    def __init__(self, predict_fn: Callable, scaler: ABCScaler, cat_idx: int, threshold: float):
        super().__init__(dist_sync_on_step=False)
        self.predict_fn = predict_fn
        self.scaler = scaler
        self.cat_idx = cat_idx
        self.threshold = threshold

        self.add_state("total_n_changes", default=torch.tensor(0), dist_reduce_fx="sum")
        self.add_state("diffs", default=torch.tensor(0), dist_reduce_fx="sum")

    def update(self, x: torch.Tensor, c: torch.Tensor, c_y: torch.Tensor):
        # inverse transform
        x_cont_inv = self.scaler.inverse_transform(x[:, :self.cat_idx])
        c_cont_inv = self.scaler.inverse_transform(c[:, :self.cat_idx])
        # a bool metrics on whether differences between x and c is smaller than the threshold
        cont_diff = torch.abs(x_cont_inv - c_cont_inv) < self.threshold
        # total nums of differences
        self.total_n_changes += torch.sum(cont_diff.any(axis=1))
        # new continous cf
        c_cont_hat = torch.where(cont_diff, x_cont_inv, c_cont_inv)
        c[:, :self.cat_idx] = self.scaler.transform(c_cont_hat)
        c_y_hat = self.predict_fn(c)

        self.diffs += (torch.round(c_y) != torch.round(c_y_hat)).sum()

    def compute(self):
        return 1 - self.diffs / self.total_n_changes, self.diffs, self.total_n_changes